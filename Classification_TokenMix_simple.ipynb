{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slucey-cs-cmu-edu/RVSS26/blob/main/Classification_TokenMix_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b09c7e3",
      "metadata": {
        "id": "6b09c7e3"
      },
      "source": [
        "# MNIST Classification with Tokenization + Separable Mixing (U across tokens, V within tokens)\n",
        "\n",
        "This notebook mirrors the fully-connected MLP notebook, but replaces each dense hidden layer on the flattened image with:\n",
        "\n",
        "1. **Tokenization**: split the 28×28 image into non-overlapping **p×p** patches (tokens).\n",
        "2. **Separable mixing layer** (repeated `depth` times):\n",
        "   - $U$ mixes **across tokens**\n",
        "   - $V$ mixes **within tokens**\n",
        "\n",
        "Mathematically, if $X ∈ R^{N×D}$ is the token matrix (N tokens, D channels per token), a layer is:\n",
        "\n",
        "$$X \\leftarrow \\eta( U X V )$$\n",
        "\n",
        "where $U ∈ R^{N×N}$ and $V ∈ R^{D×D}$.\n",
        "\n",
        "At the end, we print parameter counts so you can compare against the fully-connected baseline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986b15a4",
      "metadata": {
        "id": "986b15a4"
      },
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bddcf8ba",
      "metadata": {
        "id": "bddcf8ba"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "# Simple reproducibility (optional)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6960395",
      "metadata": {
        "id": "f6960395"
      },
      "source": [
        "## 2. Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50ad4e47",
      "metadata": {
        "id": "50ad4e47"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "# Simple reproducibility (optional)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37c6042d",
      "metadata": {
        "id": "37c6042d"
      },
      "source": [
        "## 3. Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "371384d9",
      "metadata": {
        "id": "371384d9"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean/std\n",
        "])\n",
        "\n",
        "full_train = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
        "test_set   = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_set, val_set = random_split(full_train, [50_000, 10_000], generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,  num_workers=0)\n",
        "val_loader   = DataLoader(val_set,   batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"train:\", len(train_set), \"val:\", len(val_set), \"test:\", len(test_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e795a296",
      "metadata": {
        "id": "e795a296"
      },
      "source": [
        "## 3.5 Visualize tokenization (patches)\n",
        "\n",
        "Before training, it helps to **see** what tokenization is doing.\n",
        "\n",
        "We take a few MNIST images and show:\n",
        "1. the original image\n",
        "2. the same image with a patch grid overlay\n",
        "3. the extracted patches laid out in a grid (this is the token matrix reshaped back into 2D patches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b141df9f",
      "metadata": {
        "id": "b141df9f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# ----------------------------\n",
        "# Self-contained patchify\n",
        "# ----------------------------\n",
        "def patchify_mnist_local(x, p: int):\n",
        "    B, C, H, W = x.shape\n",
        "    assert C == 1 and H == 28 and W == 28\n",
        "    patches = x.unfold(2, p, p).unfold(3, p, p)\n",
        "    Hp, Wp = patches.size(2), patches.size(3)\n",
        "    return patches.contiguous().view(B, Hp * Wp, p * p), Hp, Wp\n",
        "\n",
        "# Use model patch size if defined later, otherwise default\n",
        "p_to_show = patch_size if \"patch_size\" in globals() else 7\n",
        "print(\"Using patch size for visualization:\", p_to_show)\n",
        "\n",
        "def show_patch_grid(img_1x28x28, p: int, gap: int = 2):\n",
        "    if img_1x28x28.dim() == 3:\n",
        "        img = img_1x28x28[0].cpu().numpy()\n",
        "    else:\n",
        "        img = img_1x28x28.cpu().numpy()\n",
        "\n",
        "    img_t = torch.tensor(img).unsqueeze(0).unsqueeze(0)\n",
        "    X, Hp, Wp = patchify_mnist_local(img_t, p=p)\n",
        "    patches = X[0].reshape(Hp, Wp, p, p).cpu().numpy()\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 3))\n",
        "\n",
        "    # (1) original\n",
        "    ax1 = plt.subplot(1, 3, 1)\n",
        "    ax1.imshow(img, cmap=\"gray\")\n",
        "    ax1.set_title(f\"Original (p={p})\")\n",
        "    ax1.axis(\"off\")\n",
        "\n",
        "    # (2) grid overlay\n",
        "    ax2 = plt.subplot(1, 3, 2)\n",
        "    ax2.imshow(img, cmap=\"gray\")\n",
        "    for k in range(0, 29, p):\n",
        "        ax2.axhline(k - 0.5, linewidth=1)\n",
        "        ax2.axvline(k - 0.5, linewidth=1)\n",
        "    ax2.set_title(\"Patch grid overlay\")\n",
        "    ax2.axis(\"off\")\n",
        "\n",
        "    # (3) patches separated by gaps\n",
        "    Hm = Hp * p + (Hp - 1) * gap\n",
        "    Wm = Wp * p + (Wp - 1) * gap\n",
        "    mosaic = np.ones((Hm, Wm))  # white background\n",
        "\n",
        "    for i in range(Hp):\n",
        "        for j in range(Wp):\n",
        "            r0 = i * (p + gap)\n",
        "            c0 = j * (p + gap)\n",
        "            mosaic[r0:r0+p, c0:c0+p] = patches[i, j]\n",
        "\n",
        "    ax3 = plt.subplot(1, 3, 3)\n",
        "    ax3.imshow(mosaic, cmap=\"gray\")\n",
        "    ax3.set_title(\"Tokens shown separately\")\n",
        "    ax3.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Show a few examples\n",
        "x_batch, y_batch = next(iter(train_loader))\n",
        "for i in range(3):\n",
        "    print(f\"Label: {int(y_batch[i])}\")\n",
        "    show_patch_grid(x_batch[i], p=p_to_show, gap=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a493cfc7",
      "metadata": {
        "id": "a493cfc7"
      },
      "source": [
        "## 4. Baseline: Fully Connected MLP (for comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b9a91b0",
      "metadata": {
        "id": "4b9a91b0"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, hidden=256):\n",
        "        super().__init__()\n",
        "        self.fc0 = nn.Linear(28*28, hidden)\n",
        "        self.fc1 = nn.Linear(hidden, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)      # flatten: (B, 1, 28, 28) -> (B, 784)\n",
        "        x = F.relu(self.fc0(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        logits = self.fc2(x)\n",
        "        return logits\n",
        "\n",
        "net = MLP(hidden=256).to(device)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f90bdaca",
      "metadata": {
        "id": "f90bdaca"
      },
      "source": [
        "## 5. Tokenization + Separable Mixing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b15048",
      "metadata": {
        "id": "49b15048"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def patchify_mnist(x, p: int):\n",
        "    # x: (B,1,28,28) -> X: (B,N,D) with N=(28/p)^2, D=p^2\n",
        "    B, C, H, W = x.shape\n",
        "    assert C == 1 and H == 28 and W == 28, \"Expected MNIST shape (B,1,28,28)\"\n",
        "    assert H % p == 0 and W % p == 0, \"Patch size must divide 28\"\n",
        "    patches = x.unfold(2, p, p).unfold(3, p, p)   # (B,1,Hp,Wp,p,p)\n",
        "    Hp, Wp = patches.size(2), patches.size(3)\n",
        "    N = Hp * Wp\n",
        "    D = p * p\n",
        "    return patches.contiguous().view(B, N, D)\n",
        "\n",
        "def left_mul_tokens(X, U):\n",
        "    # X: (B,N,D), U: (N,N)  ->  U @ X  (mix across tokens)\n",
        "    B, N, D = X.shape\n",
        "    X = X.transpose(1, 2).reshape(B * D, N)  # (B·D, N)\n",
        "    X = X @ U.T                              # (B·D, N)\n",
        "    return X.reshape(B, D, N).transpose(1, 2)\n",
        "\n",
        "def right_mul_channels(X, V):\n",
        "    # X: (B,N,D), V: (D,D)  ->  X @ V  (mix within tokens)\n",
        "    B, N, D = X.shape\n",
        "    X = X.reshape(B * N, D)                  # (B·N, D)\n",
        "    X = X @ V                                # (B·N, D)\n",
        "    return X.reshape(B, N, D)\n",
        "\n",
        "class TokenMixLayer(nn.Module):\n",
        "    def __init__(self, N, D):\n",
        "        super().__init__()\n",
        "        # U mixes across tokens, V mixes within tokens\n",
        "        self.U = nn.Parameter(torch.randn(N, N) * (1.0 / (N ** 0.5)))\n",
        "        self.V = nn.Parameter(torch.randn(D, D) * (1.0 / (D ** 0.5)))\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = left_mul_tokens(X, self.U)\n",
        "        X = right_mul_channels(X, self.V)\n",
        "        return F.relu(X)\n",
        "\n",
        "class TokenMixNet(nn.Module):\n",
        "    def __init__(self, patch_size=7, depth=2, num_classes=10):\n",
        "        super().__init__()\n",
        "        p = patch_size\n",
        "        self.p = p\n",
        "        self.N = (28 // p) * (28 // p)  # number of tokens\n",
        "        self.D = p * p                  # channels per token (flattened patch)\n",
        "        self.layers = nn.ModuleList([TokenMixLayer(self.N, self.D) for _ in range(depth)])\n",
        "        self.fc = nn.Linear(self.N * self.D, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        X = patchify_mnist(x, self.p)  # (B,N,D)\n",
        "        for layer in self.layers:\n",
        "            X = layer(X)\n",
        "        X = X.reshape(x.size(0), -1)   # (B, N*D) == (B, 784)\n",
        "        return self.fc(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1893ebf7",
      "metadata": {
        "id": "1893ebf7"
      },
      "source": [
        "## 6. Parameter counting (so you can compare models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1355c9",
      "metadata": {
        "id": "6a1355c9"
      },
      "outputs": [],
      "source": [
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def pretty_int(n):\n",
        "    return f\"{n:,}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b64e81",
      "metadata": {
        "id": "91b64e81"
      },
      "source": [
        "## 7. Choose model + hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25be0bd8",
      "metadata": {
        "id": "25be0bd8"
      },
      "outputs": [],
      "source": [
        "# Choose settings\n",
        "epochs = 5\n",
        "lr = 1e-3\n",
        "\n",
        "# Baseline MLP settings (matches the original fully-connected notebook)\n",
        "mlp_hidden_dim = 256\n",
        "\n",
        "# TokenMix settings\n",
        "patch_size = 4   # try 7 (16 tokens) or 4 (49 tokens)\n",
        "token_depth = 4  # number of TokenMix layers\n",
        "\n",
        "# Create models\n",
        "mlp = MLP(hidden=mlp_hidden_dim).to(device)\n",
        "token_net = TokenMixNet(patch_size=patch_size, depth=token_depth).to(device)\n",
        "\n",
        "print(\"Baseline MLP params:\", pretty_int(count_params(mlp)))\n",
        "print(\"TokenMixNet params:\", pretty_int(count_params(token_net)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cad413b",
      "metadata": {
        "id": "4cad413b"
      },
      "source": [
        "## 8. Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb05ecaa",
      "metadata": {
        "id": "cb05ecaa"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.numel()\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00e84419",
      "metadata": {
        "id": "00e84419"
      },
      "source": [
        "## 9. Train Baseline MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6774a33",
      "metadata": {
        "id": "e6774a33"
      },
      "outputs": [],
      "source": [
        "mlp_opt = optim.Adam(mlp.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train_one_epoch(mlp, train_loader, mlp_opt)\n",
        "    acc = eval_accuracy(mlp, test_loader)\n",
        "    print(f\"Epoch {epoch:02d} | loss={loss:.4f} | test_acc={acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2847fdad",
      "metadata": {
        "id": "2847fdad"
      },
      "source": [
        "## 10. Train TokenMixNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2da3719",
      "metadata": {
        "id": "e2da3719"
      },
      "outputs": [],
      "source": [
        "token_opt = optim.Adam(token_net.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train_one_epoch(token_net, train_loader, token_opt)\n",
        "    acc = eval_accuracy(token_net, test_loader)\n",
        "    print(f\"Epoch {epoch:02d} | loss={loss:.4f} | test_acc={acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9392711",
      "metadata": {
        "id": "a9392711"
      },
      "source": [
        "## 11. Final parameter comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1791c2d1",
      "metadata": {
        "id": "1791c2d1"
      },
      "outputs": [],
      "source": [
        "print(\"Baseline MLP params:\", pretty_int(count_params(mlp)))\n",
        "print(\"TokenMixNet params:\", pretty_int(count_params(token_net)))\n",
        "\n",
        "print(\"\\nTip: Try changing `mlp_hidden_dim`, `token_depth`, and `patch_size` (7 vs 4) and rerun.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}